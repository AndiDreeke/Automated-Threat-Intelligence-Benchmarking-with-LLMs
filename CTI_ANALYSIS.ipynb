{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFcqrql-E3BQ",
        "outputId": "1e652621-ebf0-4823-8955-cc78a9be5fec",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/253.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/177.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.8/177.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.9/65.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymupdf4llm\n",
            "  Downloading pymupdf4llm-0.0.27-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf4llm-0.0.27-py3-none-any.whl (30 kB)\n",
            "Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf, pymupdf4llm\n",
            "Successfully installed pymupdf-1.26.4 pymupdf4llm-0.0.27\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
            "Collecting mistralai\n",
            "  Downloading mistralai-1.9.10-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
            "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from mistralai) (0.28.1)\n",
            "Collecting invoke<3.0.0,>=2.2.0 (from mistralai)\n",
            "  Downloading invoke-2.2.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pydantic>=2.10.3 in /usr/local/lib/python3.12/dist-packages (from mistralai) (2.11.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from mistralai) (2.9.0.post0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from mistralai) (6.0.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mistralai) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->mistralai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->mistralai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10.3->mistralai) (4.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.28.1->mistralai) (1.3.1)\n",
            "Downloading mistralai-1.9.10-py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.5/440.5 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
            "Downloading invoke-2.2.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: invoke, eval-type-backport, mistralai\n",
            "Successfully installed eval-type-backport-0.2.2 invoke-2.2.0 mistralai-1.9.10\n"
          ]
        }
      ],
      "source": [
        "# @title Dependencies\n",
        "%pip install --quiet python-docx\\\n",
        "stix2\\\n",
        "langchain-core\\\n",
        "google-generativeai\n",
        "\n",
        "%pip install -U pymupdf4llm\\\n",
        "pymupdf\n",
        "\n",
        "%pip install tiktoken\n",
        "\n",
        "%pip install mistralai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Up1cUEbADIcZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "import io\n",
        "import re\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import uuid\n",
        "import locale\n",
        "import random\n",
        "import string\n",
        "import tempfile\n",
        "from pprint import pprint\n",
        "from datetime import datetime\n",
        "from io import BytesIO\n",
        "from dataclasses import dataclass\n",
        "import glob\n",
        "import ast\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# Text and file processing libraries\n",
        "import html\n",
        "from PIL import Image\n",
        "import textwrap\n",
        "import docx\n",
        "from docx import Document\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import pymupdf4llm\n",
        "import sys, pymupdf\n",
        "\n",
        "# Third-party library imports for data manipulation and analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Visualization and display libraries\n",
        "from IPython.display import HTML, display\n",
        "import graphviz\n",
        "\n",
        "# STIX2 Cyber Threat Intelligence objects\n",
        "import stix2\n",
        "\n",
        "# Google Colab utilities\n",
        "from google.colab import userdata\n",
        "from ipywidgets import FileUpload, widgets, Output\n",
        "from IPython.display import display, Markdown\n",
        "import IPython.display\n",
        "\n",
        "# Google Gemini\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Openai\n",
        "import requests\n",
        "import httpx\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import base64\n",
        "\n",
        "from mistralai import Mistral\n",
        "\n",
        "# Langchain utilities\n",
        "from langchain_core.output_parsers.json import parse_json_markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM APIs"
      ],
      "metadata": {
        "id": "iVDxVeOZ5kHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Abstract API defintion\n",
        "\n",
        "class LlmAPI(ABC):\n",
        "    @abstractmethod\n",
        "    def __init__(self, color: str):\n",
        "        pass\n",
        "    @abstractmethod\n",
        "    def get_response(self):\n",
        "        pass\n",
        "    @abstractmethod\n",
        "    def get_full_response(self):\n",
        "        pass\n",
        "\n",
        "# Wrapper class to create unified access to llm response\n",
        "class ResponseWrapper:\n",
        "    def __init__(self, text):\n",
        "        self.text = text"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pgvUnE94U3A3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KbW6pyLKcgtX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Gemini API Class\n",
        "\n",
        "class GeminiAPI(LlmAPI):\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    Configuring and initialising gemini api\n",
        "    \"\"\"\n",
        "    genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "\n",
        "    # Set up the model\n",
        "    self.generation_config = {\n",
        "      \"temperature\": 0.1,\n",
        "      \"top_p\": 0.95,\n",
        "      \"top_k\": 64,\n",
        "      \"max_output_tokens\": 10000\n",
        "    }\n",
        "\n",
        "      # \"response_mime_type\": \"application/json\"\n",
        "\n",
        "    # Safety settings\n",
        "    self.safety_settings = [\n",
        "      {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\"\n",
        "      },\n",
        "      {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_NONE\"\n",
        "      },\n",
        "      {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_NONE\"\n",
        "      },\n",
        "      {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\"\n",
        "      },\n",
        "    ]\n",
        "\n",
        "    #Model Selector\n",
        "    self.model = genai.GenerativeModel('gemini-2.5-flash',\n",
        "                                  generation_config=self.generation_config,\n",
        "                                  safety_settings=self.safety_settings)\n",
        "\n",
        "    self.response = ''\n",
        "\n",
        "  def get_response(self, query):\n",
        "    self.response = self.model.generate_content(query)\n",
        "\n",
        "    return self.response.text\n",
        "\n",
        "  def get_full_response(self,query,images = []):\n",
        "    self.response = self.model.generate_content(self.create_gemini_content(query,images))\n",
        "    return self.response\n",
        "\n",
        "\n",
        "  def create_gemini_content(self,prompt, image_bytes_list):\n",
        "    contents = []\n",
        "    contents.append(prompt)\n",
        "    # Add images to the content. Each image is a dict with 'mime_type' and 'data'.\n",
        "    for image_bytes in image_bytes_list:\n",
        "        if image_bytes:\n",
        "            contents.append({\"mime_type\": \"image/png\", \"data\": image_bytes})\n",
        "    return contents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Groq LLaMA3 API Class\n",
        "\n",
        "class LlamaAPI(LlmAPI):\n",
        "  def __init__(self):\n",
        "    self.api_key = userdata.get(\"LLAMA_API_KEY\")\n",
        "\n",
        "    openai.api_key = self.api_key\n",
        "    openai.base_url = \"https://api.groq.com/openai/v1/\"\n",
        "    self.model_name = \"llama-3.3-70b-versatile\"\n",
        "\n",
        "    self.generation_config = {\n",
        "      \"temperature\": 0.1,\n",
        "      \"top_p\": 0.95,\n",
        "      \"max_tokens\": 8000\n",
        "    }\n",
        "\n",
        "  def get_response(self, query):\n",
        "    response = openai.chat.completions.create(\n",
        "      model=self.model_name,\n",
        "      messages=[{\"role\": \"user\", \"content\": query}],\n",
        "      **self.generation_config\n",
        "    )\n",
        "    result = response.choices[0].message.content.strip()\n",
        "    return ResponseWrapper(result) # send in .text attribute\n",
        "\n",
        "  # Images are not supported in Groq\n",
        "  def get_full_response(self, query, images=[]):\n",
        "    return self.get_response(query)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "gJH6z0jY5qzt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title DeepSeek API Class\n",
        "class DeepSeekAPI(LlmAPI):\n",
        "    def __init__(self):\n",
        "        self.client = OpenAI(api_key=userdata.get('DEEPSEEK_API_KEY'), base_url=\"https://api.chatanywhere.org/v1\")\n",
        "        self.model = \"deepseek-chat\"\n",
        "        self.response = None\n",
        "        self.temperature = 0.1\n",
        "        self.top_p = 0.95\n",
        "        self.max_tokens = 8000\n",
        "\n",
        "    def get_response(self, query):\n",
        "        completion = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": query}],\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            max_tokens=self.max_tokens\n",
        "        )\n",
        "        self.response = completion\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "\n",
        "    def get_full_response(self, query, images=[]):\n",
        "        return self.get_response(query)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "RcPNe4vfKP9C"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GPT 4.0 Class\n",
        "class OpenAIAPI(LlmAPI):\n",
        "    def __init__(self):\n",
        "        self.client = OpenAI(api_key=userdata.get('DEEPSEEK_API_KEY'), base_url=\"https://api.chatanywhere.org/v1\")\n",
        "\n",
        "        self.model = \"gpt-4o\"\n",
        "        self.response = None\n",
        "        self.temperature = 0.1\n",
        "        self.top_p = 0.95\n",
        "        self.max_tokens = 8000\n",
        "\n",
        "    def get_response(self, query):\n",
        "        completion = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": query}],\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            max_tokens=self.max_tokens\n",
        "        )\n",
        "        self.response = completion\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "    def get_full_response(self, query, image_bytes_list=[]):\n",
        "        messages = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": query}]}]\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            max_tokens=self.max_tokens\n",
        "        )\n",
        "        self.response = response\n",
        "        return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "3HskSSP2O3Fz",
        "cellView": "form"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mistral API Class\n",
        "class MistralAPI(LlmAPI):\n",
        "    def __init__(self, api_key=None, model=\"ministral-8b-latest\"):\n",
        "        if api_key is None:\n",
        "            api_key = userdata.get('MISTRAL_API_KEY')\n",
        "        self.client = Mistral(api_key=api_key)\n",
        "        self.model = model\n",
        "        self.response = ''\n",
        "\n",
        "    def get_response(self, query):\n",
        "        chat_response = self.client.chat.complete(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": query}]\n",
        "        )\n",
        "        self.response = chat_response.choices[0].message.content\n",
        "        return self.response\n",
        "\n",
        "    def get_full_response(self, query, images=[]):\n",
        "        chat_response = self.client.chat.complete(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": query}]\n",
        "        )\n",
        "        return ResponseWrapper(chat_response.choices[0].message.content)\n"
      ],
      "metadata": {
        "id": "5hFwuJV70rT_",
        "cellView": "form"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Document Parser"
      ],
      "metadata": {
        "id": "ukp4V-hj8aik"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "H3EtQsIZcJaw"
      },
      "outputs": [],
      "source": [
        "class DocumentProcessor:\n",
        "    def __init__(self, title=None):\n",
        "        #State variable for content initialation\n",
        "        self.initial_processing = True\n",
        "\n",
        "        #Set Incident Title\n",
        "        self.incident_title = title\n",
        "\n",
        "        self.pages_to_exclude = set()\n",
        "        self.files_content = {}\n",
        "        self.upload_widget = None\n",
        "        self.setup_simple_widgets()\n",
        "        self.upload_widget.observe(self.on_file_upload, names='value')\n",
        "\n",
        "    def setup_simple_widgets(self):\n",
        "        if self.upload_widget is not None:\n",
        "          self.upload_widget.value.clear()\n",
        "          self.upload_widget._counter = 0\n",
        "        self.upload_widget = FileUpload(multiple=True)\n",
        "        display(self.upload_widget)\n",
        "\n",
        "    def on_file_upload(self, change):\n",
        "        self.process_files()\n",
        "\n",
        "    def parse_text(self, file_name: str, content: io.BytesIO) -> str:\n",
        "        text = None\n",
        "        tables = None\n",
        "        images = None\n",
        "        if file_name.endswith('.pdf'):\n",
        "            text,images = self.handle_pdf(content,file_name)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file type: {file_name}\")\n",
        "\n",
        "        cleaned_text = re.sub(r'\\s+', ' ', text).strip()\n",
        "        return cleaned_text, tables, images\n",
        "\n",
        "    def handle_pdf(self,content,file_name):\n",
        "      document = pymupdf.open(stream=content)\n",
        "      images = []\n",
        "\n",
        "      #Image Extraction\n",
        "      for page_index in range(len(document)):\n",
        "          page = document[page_index]\n",
        "          for img_index, img in enumerate(page.get_images(full=True), start=1):\n",
        "              xref = img[0]\n",
        "              base_image = document.extract_image(xref)\n",
        "\n",
        "              image_bytes = base_image[\"image\"]\n",
        "              image_ext = base_image[\"ext\"]\n",
        "              images.append(image_bytes)\n",
        "\n",
        "      #Text to Markdown\n",
        "      md_text = pymupdf4llm.to_markdown(document)\n",
        "\n",
        "      return md_text,images\n",
        "\n",
        "    def process_files(self):\n",
        "        #Initialise\n",
        "        if self.initial_processing:\n",
        "          self.files_content['name'] = \"\"\n",
        "          self.files_content['content'] = \"\"\n",
        "          self.files_content['tables'] = \"\"\n",
        "          self.files_content['images'] = []\n",
        "          self.initial_processing = False\n",
        "\n",
        "        for name, content in self.upload_widget.value.items():\n",
        "            text, tables, images = self.parse_text(name, io.BytesIO(content['content']))\n",
        "            self.files_content['name'] = name\n",
        "            self.files_content['content'] = self.files_content['content'] + text\n",
        "            self.files_content['tables'] = tables\n",
        "            self.files_content['images'].extend(images)\n",
        "            print(f\"File Processed!: {name}\")\n",
        "\n",
        "        print(\"Processing Completed!\")\n",
        "\n",
        "    # Iterate the created pdf_images folder and load every image in bytes format\n",
        "    def proccess_images(self):\n",
        "      img_data = []\n",
        "      for filename in glob.iglob('./pdf_images/' + '**/*.png', recursive=True):\n",
        "          with open(filename, \"rb\") as img_file:\n",
        "            img_data.append(img_file.read())\n",
        "      return img_data\n",
        "\n",
        "    def get_processed_texts(self):\n",
        "        return self.files_content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFZIJGnPvOE1"
      },
      "source": [
        "# Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "id": "OKMLrNimuWaZ",
        "jupyter": {
          "outputs_hidden": true
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "7698d32d-fab9-4c6a-8ca0-d69d13a0b5e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:43: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:43: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-456452063.py:43: SyntaxWarning: invalid escape sequence '\\ '\n"
          ]
        }
      ],
      "source": [
        "# @title Summarise report query\n",
        "def report_query(processed_texts):\n",
        " return f\"\"\"\n",
        "Your task is to process the given section of a Cyber Threat Intelligence (CTI) report from the viewpoint of a cybersecurity analyst with significant expertise in the MITRE ATT&CK framework and recreate the attack flow.\n",
        "\n",
        "In order to achieve this, you should do the following:\n",
        "* Analyze the text sentence-by-sentence, if and when necessary, consider additional sentences for context, to identify specific actions taken by attackers.\n",
        "* Consider only the report as source before creating your response\n",
        "* Work out the initial attack, which was used to gain access to the system and made the subsequent attacks viable.\n",
        "* Include each and every step the attackers take, any and all steps, both the obvious and subtle.\n",
        "* Hierarchy of prerequisite attacks should be mostly linear, as these are steps taken in order, with occasional branching and rejoining.\n",
        "* Ensure compilation of all the assets compromised in the attack, even the most minor asset compromised should be noted.\n",
        "* Be as detailed as possible when listing all techniques, if an asset is compromised, the system compromised to achieve this should be noted.\n",
        "* Any specific script/program/malware used must be noted and added to assets.\n",
        "\n",
        "For each action/step identified, you will output information in JSON format with the following structure:\n",
        "\n",
        "1. Action Name: The specific technique utlised/action taken by the attacker, as described in the text, like 'Vulnerability Scanning', 'Exploit Public-Facing Application', etc.\n",
        "2. Tactic ID: The Tactic ID from the MITRE ATT&CK framework that categorizes the overarching goal of the action (e.g., TA0001 for Initial Access).\n",
        "3. Technique ID/Sub-technique ID: The specific Technique or Sub-technique ID from the MITRE ATT&CK framework that the action corresponds to.\n",
        "4. Label(s): the technique concatenated with the Technique id, with a singular hyphen between, returned as an array with a single element (eg. [\"Spearphishing Attachment - T1566\"])\n",
        "5. Affected Assets: The asset(s) targeted or compromised by the action, based on the report's context.\n",
        "6. Prerequisite: the action name and technqiue id of any technique that must be completed previously in the attack for this step to take place. If there are no prerequisites, leave the array empty\n",
        "\n",
        "Your response should be structured as follows (sample JSON for guidance):\n",
        "{{techniques[\n",
        "{{\n",
        "  \"action_name\": \"Example technique\",\n",
        "  \"tactic_id\": \"TA000X\",\n",
        "  \"technique_id\": \"TXXXX\",\n",
        "  \"label\":[\"action_name\"-\"technique_id\"],\n",
        "  \"affected_assets\": [\"Example Affected Asset 1\",\"Example Affected Asset 2\"],\n",
        "  \"prerequisite\": [\"Action Name - Technqiue ID Prior Action in the flow\"]\n",
        "}}\n",
        "]\n",
        "}}\n",
        "If you use double quotes (\\\") in any results, please escape them with \\ to avoid poor JSON formating.\n",
        "Respond with only the required JSON, DO NOT include any preamble or other comments, return only the JSON.\n",
        "\n",
        "{processed_texts}\n",
        "\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Minimal report query\n",
        "def report_query_minimal(processed_texts):\n",
        " return f\"\"\"\n",
        "Process the given section of a Cyber Threat Intelligence (CTI) report and identify all attacker actions associated with MITRE ATT&CK techniques to recreate the attack flow.\n",
        "Output the findings in JSON format containing:\n",
        "\n",
        "{{techniques[\n",
        "{{\n",
        "  \"action_name\": \"Example technique\",\n",
        "  \"tactic_id\": \"TA000X\",\n",
        "  \"technique_id\": \"TXXXX\",\n",
        "  \"label\":[\"action_name\"-\"technique_id\"],\n",
        "  \"affected_assets\": [\"Example Affected Asset 1\",\"Example Affected Asset 2\"],\n",
        "  \"prerequisite\": [\"Action Name - Technqiue ID Prior Action in the flow\"]\n",
        "}}\n",
        "]\n",
        "}}\n",
        "\n",
        "\n",
        "If you use double quotes (\\\") in any results, please escape them with \\ to avoid poor JSON formating.\n",
        "\n",
        "Respond with only the required JSON, DO NOT include any preamble or other comments, return only the JSON.\n",
        "\n",
        "{processed_texts}\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4He_OHQ8mfEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "bc57df18-b3d2-4a02-990d-9e0cdefd0e2c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:29: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:29: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-252738415.py:29: SyntaxWarning: invalid escape sequence '\\ '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Moderate report query\n",
        "def report_query_moderate(processed_texts):\n",
        " return f\"\"\"\n",
        "Process the given section of a Cyber Threat Intelligence (CTI) report and identify all attacker actions associated with MITRE ATT&CK techniques to recreate the attack flow from the perspective of a cybersecurity analyst familiar with the MITRE ATT&CK framework.\n",
        "Identify attacker actions in the order they occurred, along with affected assets and any prerequisites between actions.\n",
        "When assigning MITRE techniques, be as precise as possible based only on the report’s content.\n",
        "Output your findings in JSON format with:\n",
        "Action Name\n",
        "Tactic ID\n",
        "Technique ID/Sub-technique ID\n",
        "Label(s)\n",
        "Affected Assets\n",
        "Prerequisites\n",
        "\n",
        "{{techniques[\n",
        "{{\n",
        "  \"action_name\": \"Example technique\",\n",
        "  \"tactic_id\": \"TA000X\",\n",
        "  \"technique_id\": \"TXXXX\",\n",
        "  \"label\":[\"action_name\"-\"technique_id\"],\n",
        "  \"affected_assets\": [\"Example Affected Asset 1\",\"Example Affected Asset 2\"],\n",
        "  \"prerequisite\": [\"Action Name - Technqiue ID Prior Action in the flow\"]\n",
        "}}\n",
        "]\n",
        "}}\n",
        "\n",
        "\n",
        "If you use double quotes (\\\") in any results, please escape them with \\ to avoid poor JSON formating.\n",
        "\n",
        "Respond with only the required JSON, DO NOT include any preamble or other comments, return only the JSON.\n",
        "\n",
        "{processed_texts}\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OyEElt1YsInk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "687de00e-61da-4c67-926f-0fc70e0d0e5c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:37: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:37: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-3323434135.py:37: SyntaxWarning: invalid escape sequence '\\ '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wrapper\n"
      ],
      "metadata": {
        "id": "mJeVSIViVDMl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "GPp37ALY9C1-"
      },
      "outputs": [],
      "source": [
        "class Output:\n",
        "  def __init__(self, doc_processor, model=\"gemini\"):\n",
        "    #Define Model\n",
        "    if model == \"llama\":\n",
        "      self.model = LlamaAPI()\n",
        "    elif model == \"gemini\":\n",
        "      self.model = GeminiAPI()\n",
        "    elif model == \"deepseek\":\n",
        "      self.model = DeepSeekAPI()\n",
        "    elif model == \"gpt\":\n",
        "      self.model = OpenAIAPI()\n",
        "    elif model ==\"mistral\":\n",
        "      self.model = MistralAPI()\n",
        "\n",
        "    #Get Data\n",
        "    self.doc_processor = doc_processor\n",
        "    self.doc_object = doc_processor.get_processed_texts()\n",
        "    self.doc_name,extension = self.doc_object['name'].split(\".\")\n",
        "    self.processed_texts = self.doc_object['content']\n",
        "    self.processed_images = self.doc_object['images']\n",
        "\n",
        "    #Query\n",
        "    self.query = report_query(self.processed_texts)\n",
        "\n",
        "    self.report_summarised = self.model.get_full_response(self.query,self.processed_images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wOX2ZNRu4Rv"
      },
      "source": [
        "# Output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Full File Upload (Unlimited Input)\n",
        "#Parameter title=\"\"  || set value to be shown on top of graph\n",
        "doc_processor = DocumentProcessor(title=\"Swift\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "3dfd3873ee574af39d6c6061826efe3b",
            "ce3b7a0d994844759e43ef5df28d0247",
            "bd5de4cd90ac4901adc538b8e96b3375"
          ]
        },
        "id": "QKHVoSHLV6Hp",
        "outputId": "64122517-b3de-4bdf-edd0-d6e638058d8b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, description='Upload', multiple=True)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3dfd3873ee574af39d6c6061826efe3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Processed!: Sony_Source_.pdf\n",
            "Processing Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "6c77f1b62f2e42cd90a96c8f3d99657a",
            "f79107e64fa84761aeec455ad48aa262",
            "4eb19d4c007e449784656337bca8a4b5"
          ]
        },
        "id": "Qz5kPbhOQ1hp",
        "outputId": "1e331a18-910a-42ff-98e3-f95cab3f4a38"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, description='Upload', multiple=True)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c77f1b62f2e42cd90a96c8f3d99657a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Processed!: Sony_Source_.pdf\n",
            "Processing Completed!\n"
          ]
        }
      ],
      "source": [
        "# @title Mininmum File Upload(Small Input)\n",
        "doc_processor_small = DocumentProcessor(title=\"Swift\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Medium File Upload(Moderate Input)\n",
        "doc_processor_medium = DocumentProcessor(title=\"Swift\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "0432c639e10546e58dc8968a961733a0",
            "c75152439a6444228ba9461037742dfb",
            "3ed654974e9f41c7a74683946aec13fb"
          ]
        },
        "id": "zat-ZqU8ZJvx",
        "outputId": "a5b7ba8b-1cb5-4358-bb6a-09c1f2d622f7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileUpload(value={}, description='Upload', multiple=True)"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0432c639e10546e58dc8968a961733a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Processed!: Source2.pdf\n",
            "Processing Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment"
      ],
      "metadata": {
        "id": "jjWEm_qI8gN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Helper Variables\n",
        "\n",
        "counter_llama = 0\n",
        "counter_gemini = 0\n",
        "counter_deepseek = 0\n",
        "counter_gpt = 0\n",
        "counter_mistral = 0"
      ],
      "metadata": {
        "id": "jU-B5kQmYdur"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0DtWnSHGZvsk",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title LLAMA\n",
        "counter_llama += 1\n",
        "o = Output(doc_processor_small,\"llama\")\n",
        "json_start = o.report_summarised.text.find('{')\n",
        "json_end = o.report_summarised.text.rfind('```')\n",
        "json_text = o.report_summarised.text[json_start:json_end].strip()\n",
        "data = json.loads(json_text+\"}\")\n",
        "\n",
        "with open(f\"{doc_processor.incident_title}_LLama_{counter_llama}.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "  json.dump(data, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GEMINI\n",
        "\n",
        "counter_gemini += 1\n",
        "o = Output(doc_processor_small,\"gemini\")\n",
        "text = o.report_summarised.text.strip()\n",
        "if text.startswith(\"```json\"):\n",
        "    text = text[len(\"```json\"):].strip()\n",
        "if text.endswith(\"```\"):\n",
        "    text = text[:-3].strip()\n",
        "data = json.loads(text)\n",
        "with open(f\"{doc_processor_medium.incident_title}_Gemini_{counter_gemini}.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data, f, indent=2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "yDAKkK7U8s2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title DeepSeek\n",
        "counter_deepseek += 1\n",
        "o = Output(doc_processor_small,\"deepseek\")\n",
        "cleaned_string = o.report_summarised.strip('`').lstrip('json').strip()\n",
        "data = json.loads(cleaned_string)\n",
        "with open(f\"{doc_processor.incident_title}_DeepSeek_{counter_deepseek}.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data, f, indent=2)"
      ],
      "metadata": {
        "id": "4zyLzdt4La8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mistral\n",
        "counter_mistral += 1\n",
        "o = Output(doc_processor,\"mistral\")\n",
        "cleaned_string = o.report_summarised.text.strip('`').lstrip('json').strip()\n",
        "data = json.loads(cleaned_string)\n",
        "with open(f\"{doc_processor.incident_title}_MISTRAL_{counter_mistral}.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data, f, indent=2)"
      ],
      "metadata": {
        "id": "LJvO5rcU08q4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de03f3fc-3b85-487a-c7e7-ccd757de6f11",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠ Images are ignored for Ministral 8B model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GPT\n",
        "counter_gpt += 1\n",
        "o = Output(doc_processor_small,\"gpt\")\n",
        "cleaned_string = o.report_summarised.strip('`').lstrip('json').strip()\n",
        "data = json.loads(cleaned_string)\n",
        "with open(f\"{doc_processor.incident_title}_GPT_{counter_gpt}.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(data, f, indent=2)\n"
      ],
      "metadata": {
        "id": "yNawlAYNPRyT",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "ukp4V-hj8aik",
        "LFZIJGnPvOE1",
        "mJeVSIViVDMl"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0432c639e10546e58dc8968a961733a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": "",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_c75152439a6444228ba9461037742dfb",
            "metadata": [
              {
                "name": "Source2.pdf",
                "type": "application/pdf",
                "size": 117445,
                "lastModified": 1755147654443
              }
            ],
            "multiple": true,
            "style": "IPY_MODEL_3ed654974e9f41c7a74683946aec13fb"
          }
        },
        "c75152439a6444228ba9461037742dfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ed654974e9f41c7a74683946aec13fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3dfd3873ee574af39d6c6061826efe3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": "",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_ce3b7a0d994844759e43ef5df28d0247",
            "metadata": [
              {
                "name": "Sony_Source_.pdf",
                "type": "application/pdf",
                "size": 168842,
                "lastModified": 1752728287285
              }
            ],
            "multiple": true,
            "style": "IPY_MODEL_bd5de4cd90ac4901adc538b8e96b3375"
          }
        },
        "ce3b7a0d994844759e43ef5df28d0247": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd5de4cd90ac4901adc538b8e96b3375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6c77f1b62f2e42cd90a96c8f3d99657a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": "",
            "button_style": "",
            "data": [
              null
            ],
            "description": "Upload",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "upload",
            "layout": "IPY_MODEL_f79107e64fa84761aeec455ad48aa262",
            "metadata": [
              {
                "name": "Sony_Source_.pdf",
                "type": "application/pdf",
                "size": 168842,
                "lastModified": 1752728287285
              }
            ],
            "multiple": true,
            "style": "IPY_MODEL_4eb19d4c007e449784656337bca8a4b5"
          }
        },
        "f79107e64fa84761aeec455ad48aa262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb19d4c007e449784656337bca8a4b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
