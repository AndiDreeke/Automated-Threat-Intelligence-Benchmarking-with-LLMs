# Benchmarking for Automated Threat Intelligence Analysis with relevant Large Language Models

The content in Benchmark_Report.pdf creates a benchmark for the
capabilities of publicly available models to reconstruct incident
kill chains from real-world cyber attack reports using the MITRE
ATT&CK Flow framework. Each model is evaluated based on
confusion matrix metrics for the rubrics of MITRE technique
mapping, cyber context understanding, and general flow recon-
structions. In addition to determining the best performing model,
the result analysis also explores the structure and content of good
and bad CTI reports for automated LLM processing.

## Models
- LLaMa
- Gemini
- GPT
- Mistral
- DeepSeek

